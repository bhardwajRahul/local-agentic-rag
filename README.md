## Local Agentic RAG using Langchain and Agno

<img width="1366" alt="Screenshot 2025-02-17 at 18 44 16" src="https://github.com/user-attachments/assets/d05fc619-a60d-4d65-ac30-d94f2db1a63d" />

Learn how to build a Retrieval-Augmented Generation (RAG) system to chat with your data using Langchain and Agno (formerly known as Phidata) completely locally, without relying on OpenAI or Gemini API keys.

In this step-by-step guide, you'll discover how to:

- Set up a local RAG pipeline i.e., Chat with Website for enhanced data privacy and control.
- Utilize Langchain and Agno to orchestrate your Agentic RAG.
- Implement Qdrant for vector storage and retrieval.
- Generate embeddings locally with FastEmbed (by Qdrant) for lightweight-fast performance.
- Run Large Language Models (LLMs) locally using Ollama. [might be slow based on device]

### Video: [https://www.youtube.com/watch?v=qOD_BPjMiwM](https://www.youtube.com/watch?v=qOD_BPjMiwM)
